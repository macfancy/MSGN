{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1469e-96bc-4ab9-89c9-9489df8a837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gamma, digamma, polygamma\n",
    "from scipy.stats import kstest\n",
    "from scipy.integrate import quad\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.neighbors import KernelDensity, NearestNeighbors\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def safe_log(x, epsilon=1e-10):\n",
    "    return np.log(np.maximum(x, epsilon))\n",
    "\n",
    "def h(x, mu, sigma, r, b, epsilon=1e-10):\n",
    "    b_safe = np.maximum(b, epsilon)\n",
    "    sigma_safe = np.maximum(sigma, epsilon)\n",
    "    term1 = b_safe / (gamma(1 / b_safe) * sigma_safe * 2 ** (1 + 1 / b_safe))\n",
    "    sign_term = 1 + r * np.sign(x - mu)\n",
    "    sign_term = np.maximum(sign_term, epsilon)\n",
    "    b_safe = np.maximum(b_safe, epsilon)\n",
    "    denominator = 2 * (sigma_safe ** b_safe) * sign_term ** b_safe\n",
    "    abs_diff = np.abs(x - mu) ** b_safe\n",
    "    term2 = np.exp(-abs_diff / np.maximum(denominator, epsilon))\n",
    "    return term1 * term2\n",
    "\n",
    "def weight(x, mu, sigma, r, b):\n",
    "    epsilon = 1e-8\n",
    "    max_value = 1e4\n",
    "    base_abs = np.maximum(np.abs(x - mu), epsilon)\n",
    "    base_sgn = np.maximum(np.abs(1 + r * np.sign(x - mu)), epsilon)\n",
    "    base_abs = np.minimum(base_abs, max_value)\n",
    "    base_sgn = np.minimum(base_sgn, max_value)\n",
    "    weight_value = (base_abs ** (b - 2) + epsilon) / (base_sgn ** b + epsilon)\n",
    "    weight_value = np.minimum(weight_value, max_value)\n",
    "    return weight_value\n",
    "\n",
    "def update_pi(q):\n",
    "    return np.mean(q, axis=0)\n",
    "\n",
    "def update_mu(data, q, mu, sigma, r, b):\n",
    "    weights = np.zeros(len(q))\n",
    "    result = 0\n",
    "    result2 = 0\n",
    "    for i in range(len(q)):\n",
    "        weights[i] = weight(data[i], mu, sigma, r, b)\n",
    "        result += q[i] * weights[i]\n",
    "        result2 += q[i] * weights[i] * data[i]\n",
    "    return result2 / result\n",
    "\n",
    "def update_sigma(data, pi, q, mu, sigma, r, b):\n",
    "    weights = np.zeros(len(q))\n",
    "    result = 0\n",
    "    for i in range(len(q)):\n",
    "        weights[i] = weight(data[i], mu, sigma, r, b)\n",
    "        result += q[i] * weights[i] * ((data[i] - mu) ** 2)\n",
    "    denominator = 2 * len(q) * pi\n",
    "    return (b * result / denominator) ** (1 / b)\n",
    "\n",
    "def update_r(data, q, mu, r, b):\n",
    "    epsilon = 1e-8\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for i in range(len(q)):\n",
    "        pos_part = (data[i] >= mu).astype(float) * ((np.maximum(data[i] - mu, 0)) ** b)\n",
    "        neg_part = (data[i] < mu).astype(float) * ((np.maximum(mu - data[i], 0)) ** b)\n",
    "        numerator += q[i] * pos_part\n",
    "        denominator += q[i] * neg_part\n",
    "    if denominator < epsilon:\n",
    "        return 0\n",
    "    log_numerator = np.log(numerator + epsilon)\n",
    "    log_denominator = np.log(denominator + epsilon)\n",
    "    ratio = np.exp((log_numerator - log_denominator) / (b + 1))\n",
    "    r_new = 1 - 2 / (ratio + 1)\n",
    "    r_new = np.clip(r_new, -1, 1)\n",
    "    return r_new\n",
    "\n",
    "def f(x, mu, sigma, r, b, epsilon=1e-8):\n",
    "    return np.abs(x - mu) / (sigma * (1 + r * np.sign(x - mu)) + epsilon)\n",
    "\n",
    "def update_b(data, pi, q, mu, sigma, r, b, max_iter=10):\n",
    "    term2 = 0\n",
    "    term4 = 0\n",
    "    for i in range(len(q)):\n",
    "        f_value = f(data[i], mu, sigma, r, b)\n",
    "        log_f_value = safe_log(f_value)\n",
    "        f_value_clipped = np.clip(f_value, 1e-5, 1e5)\n",
    "        log_f_value_clipped = np.clip(log_f_value, -1e5, 1e5)\n",
    "        term2 += q[i] * (f_value_clipped ** b) * log_f_value_clipped\n",
    "        term4 += q[i] * (f_value_clipped ** b) * log_f_value_clipped ** 2\n",
    "    term1 = (1 / b + np.log(2) / (b ** 2) + digamma(1 / b) / (b ** 2))\n",
    "    G = len(data) * pi * term1 - 0.5 * term2\n",
    "    term3 = (1 / (b ** 2) + 2 * np.log(2) / (b ** 3) + 2 * digamma(1 / b) / (b ** 3) + polygamma(1, 1 / b) / (b ** 4))\n",
    "    H = -len(data) * pi * term3 - 0.5 * term4\n",
    "    b_new = b - G / H\n",
    "    return b_new\n",
    "\n",
    "def log_likelihood(data, q, pi, mu, sigma, r, b, epsilon=1e-10, max_value=1e5, max_exp=500):\n",
    "    n, K = q.shape\n",
    "    likelihood = 0\n",
    "    for i in range(n):\n",
    "        for j in range(K):\n",
    "            ln_bj = safe_log(b[j], epsilon)\n",
    "            ln_term = (1 + 1 / b[j]) * np.log(2)\n",
    "            gamma_term = safe_log(gamma(1 / b[j]), epsilon)\n",
    "            sigma_term = safe_log(sigma[j], epsilon)\n",
    "            q_term = safe_log(np.maximum(q[i, j], epsilon), epsilon)\n",
    "            abs_diff = (np.abs(data[i] - mu[j])) ** b[j]\n",
    "            abs_diff = np.minimum(abs_diff, max_value)\n",
    "            denominator = 2 * (sigma[j] ** b[j]) * ((1 + r[j] * np.sign(data[i] - mu[j])) ** b[j])\n",
    "            denominator = np.minimum(denominator, max_value)\n",
    "            term2 = np.exp(-np.minimum(abs_diff / np.maximum(denominator, epsilon), max_exp))\n",
    "            likelihood += q[i, j] * (ln_bj - ln_term - gamma_term - sigma_term - q_term - term2)\n",
    "    return likelihood\n",
    "\n",
    "def em_algorithm(data, initial_params, max_iter=300, tol=1e-9, max_delta=0.1):\n",
    "    pi, mu, sigma, r, b = initial_params\n",
    "    K = len(pi)\n",
    "    n = len(data)\n",
    "    q = np.zeros((n, K))\n",
    "    log_likelihood_prev = -np.inf\n",
    "    for t in range(max_iter):\n",
    "        for j in range(K):\n",
    "            q[:, j] = pi[j] * h(data, mu[j], sigma[j], r[j], b[j])\n",
    "        q_sum = q.sum(axis=1, keepdims=True)\n",
    "        q_sum = np.maximum(q_sum, 1e-10)\n",
    "        q /= q_sum\n",
    "        pi_new = np.zeros(K)\n",
    "        mu_new = np.zeros(K)\n",
    "        sigma_new = np.zeros(K)\n",
    "        r_new = np.zeros(K)\n",
    "        b_new = np.zeros(K)\n",
    "        for j in range(K):\n",
    "            if K == 1:\n",
    "                pi_new = [1.0]\n",
    "            else:\n",
    "                pi_new[j] = update_pi(q[:, j])\n",
    "            mu_new[j] = update_mu(data, q[:, j], mu[j], sigma[j], r[j], b[j])\n",
    "            sigma_new[j] = update_sigma(data, pi_new[j], q[:, j], mu_new[j], sigma[j], r[j], b[j])\n",
    "            r_new[j] = update_r(data, q[:, j], mu_new[j], r[j], b[j])\n",
    "            b_new[j] = update_b(data, pi_new[j], q[:, j], mu_new[j], sigma_new[j], r_new[j], b[j])\n",
    "        pi = pi_new\n",
    "        mu = mu_new\n",
    "        sigma = sigma_new\n",
    "        r = r_new\n",
    "        b = b_new\n",
    "        log_likelihood_curr = log_likelihood(data, q, pi, mu, sigma, r, b)\n",
    "        if t > 0 and np.abs(log_likelihood_curr / log_likelihood_prev - 1) < tol:\n",
    "            break\n",
    "        log_likelihood_prev = log_likelihood_curr\n",
    "    return pi, mu, sigma, r, b, log_likelihood_curr\n",
    "\n",
    "def generalized_skew_normal_pdf(x, mu, sigma, b, r):\n",
    "    normalization = b / (2 ** (1 + 1 / b) * gamma(1 / b) * sigma)\n",
    "    h_val = np.abs(x - mu) / (sigma * (1 + r * np.sign(x - mu)))\n",
    "    pdf = normalization * np.exp(-h_val ** b / 2)\n",
    "    return pdf\n",
    "\n",
    "def generalized_skew_normal_rvs(mu, sigma, b, r, size):\n",
    "    samples = []\n",
    "    while len(samples) < size:\n",
    "        x_candidate = np.random.uniform(mu - 20 * sigma, mu + 20 * sigma)\n",
    "        u = np.random.uniform(0, 1)\n",
    "        if u < generalized_skew_normal_pdf(x_candidate, mu, sigma, b, r):\n",
    "            samples.append(x_candidate)\n",
    "    return np.array(samples)\n",
    "\n",
    "def ks_test_mixture(data, pi, mu, sigma, b, r, size):\n",
    "    n_components = len(b)\n",
    "    samples = []\n",
    "    for i in range(n_components):\n",
    "        samples_i = generalized_skew_normal_rvs(mu[i], sigma[i], b[i], r[i], size=size)\n",
    "        samples.append(samples_i)\n",
    "    samples_mixed = []\n",
    "    for i in range(n_components):\n",
    "        num_samples = int(pi[i] * size)\n",
    "        samples_mixed.append(samples[i][:num_samples])\n",
    "    samples_mixed1 = np.concatenate(samples_mixed)\n",
    "    ks_statistic, p_value = stats.ks_2samp(data, samples_mixed1)\n",
    "    return ks_statistic, p_value\n",
    "\n",
    "def sgn_log_likelihood(theta, x):\n",
    "    mu, sigma, r, b = theta\n",
    "    n = len(x)\n",
    "    if sigma <= 0 or b <= 0:\n",
    "        return -np.inf\n",
    "    denominator = sigma * (1 + r * np.sign(x - mu))\n",
    "    if np.any(denominator == 0):\n",
    "        return -np.inf\n",
    "    h_val = np.abs(x - mu) / denominator\n",
    "    try:\n",
    "        log_likelihood = (-n * ((1 + 1 / b) * np.log(2) + gamma(1 / b) + np.log(sigma) - np.log(b)) - np.sum(1 / 2 * h_val ** b))\n",
    "    except ValueError:\n",
    "        return -np.inf\n",
    "    return log_likelihood\n",
    "\n",
    "def detect_kde_peaks(samples_mixed, height=0.01, grid_n=1000):\n",
    "    samples_mixed2 = np.array(samples_mixed).reshape(-1, 1)\n",
    "    n_samples = len(samples_mixed2)\n",
    "    std_dev = np.std(samples_mixed2)\n",
    "    bandwidth_kde = 1.06 * std_dev * (n_samples ** (-1 / 5))\n",
    "    kde = KernelDensity(bandwidth=bandwidth_kde).fit(samples_mixed2)\n",
    "    x_vals = np.linspace(np.min(samples_mixed2), np.max(samples_mixed2), grid_n)\n",
    "    log_density = kde.score_samples(x_vals.reshape(-1, 1))\n",
    "    density = np.exp(log_density)\n",
    "    peaks, props = find_peaks(density, height=height)\n",
    "    peak_positions = x_vals[peaks]\n",
    "    peak_heights = props.get(\"peak_heights\", density[peaks])\n",
    "    return samples_mixed2, peak_positions, peak_heights\n",
    "\n",
    "def return_initialparams_for_K(samples_mixed, K_target, height=0.01):\n",
    "    def half_range_mode_auto_h(data):\n",
    "        data = np.sort(data)\n",
    "        n = len(data)\n",
    "        m = max(1, n // 2)\n",
    "        data_range = np.max(data) - np.min(data)\n",
    "        h_val = data_range / m\n",
    "        max_count = 0\n",
    "        mode_estimate = None\n",
    "        for i in range(n):\n",
    "            j = i\n",
    "            while j < n and data[j] <= data[i] + h_val:\n",
    "                j += 1\n",
    "            count = j - i\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                mode_estimate = (data[i] + data[j - 1]) / 2\n",
    "        return mode_estimate, h_val\n",
    "\n",
    "    samples_mixed2, peak_positions, peak_heights = detect_kde_peaks(samples_mixed, height=height)\n",
    "    if len(peak_positions) == 0 or len(peak_positions) < K_target:\n",
    "        peak_positions = np.array([np.mean(samples_mixed2)])\n",
    "        K_target = 1\n",
    "    order = np.argsort(-peak_heights)\n",
    "    chosen = order[:K_target]\n",
    "    peak_positions = peak_positions[chosen]\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(peak_positions.reshape(-1, 1))\n",
    "    _, labels = nn.kneighbors(samples_mixed2)\n",
    "    labels = labels.flatten()\n",
    "    cluster_sizes = np.bincount(labels, minlength=K_target)\n",
    "    total_points = len(samples_mixed2)\n",
    "    pi_init = cluster_sizes / total_points\n",
    "    pi_init = np.maximum(pi_init, 1e-12)\n",
    "    pi_init = pi_init / np.sum(pi_init)\n",
    "    mu_init = np.zeros(K_target, dtype=np.float64)\n",
    "    sigma_init = np.zeros(K_target, dtype=np.float64)\n",
    "    r_init = np.zeros(K_target, dtype=np.float64)\n",
    "    b_init = np.zeros(K_target, dtype=np.float64)\n",
    "    for k in range(K_target):\n",
    "        cluster_points = samples_mixed2[labels == k].flatten()\n",
    "        if len(cluster_points) == 0:\n",
    "            mu_init[k] = float(np.mean(samples_mixed2))\n",
    "            sigma_init[k] = float(np.std(samples_mixed2) + 1e-8)\n",
    "            r_init[k] = 0.0\n",
    "            b_init[k] = 2.0\n",
    "            continue\n",
    "        mode, _ = half_range_mode_auto_h(cluster_points)\n",
    "        mu_init[k] = mode\n",
    "        sigma_init[k] = np.sqrt(np.mean((cluster_points - mu_init[k]) ** 2))\n",
    "        sigma_init[k] = max(sigma_init[k], 0.1)\n",
    "        I = (cluster_points <= mu_init[k]).astype(int)\n",
    "        r_init[k] = 1 - 2 * np.mean(I)\n",
    "        b_values = np.linspace(0.1, 100, 10000)\n",
    "        likelihoods = []\n",
    "        for b_val in b_values:\n",
    "            theta = (mu_init[k], sigma_init[k], r_init[k], b_val)\n",
    "            likelihoods.append(sgn_log_likelihood(theta, cluster_points))\n",
    "        b_init[k] = b_values[int(np.argmax(likelihoods))]\n",
    "    return (pi_init, mu_init, sigma_init, r_init, b_init)\n",
    "\n",
    "def fit_best_by_ks(data, samples_mixed, ks_size=2000, height=0.01, em_max_iter=300, em_tol=1e-9):\n",
    "    _, peak_positions, _ = detect_kde_peaks(samples_mixed, height=height)\n",
    "    k_peaks_raw = len(peak_positions)\n",
    "    if k_peaks_raw <= 0:\n",
    "        k_peaks_raw = 1\n",
    "    results = []\n",
    "    best = None\n",
    "    for K in range(k_peaks_raw, 0, -1):\n",
    "        initial_params = return_initialparams_for_K(samples_mixed, K_target=K, height=height)\n",
    "        pi, mu, sigma, r, b, ll = em_algorithm(data, initial_params, max_iter=em_max_iter, tol=em_tol)\n",
    "        ks_stat, p_value = ks_test_mixture(data, pi, mu, sigma, b, r, size=ks_size)\n",
    "        rec = {\"K\": K, \"p_value\": p_value, \"ks_stat\": ks_stat, \"pi\": pi, \"mu\": mu, \"sigma\": sigma, \"r\": r, \"b\": b, \"loglik\": ll}\n",
    "        results.append(rec)\n",
    "        if best is None or p_value > best[\"p_value\"]:\n",
    "            best = rec\n",
    "    for rec in results:\n",
    "        print(f\"K={rec['K']}, KS={rec['ks_stat']:.6g}, p-value={rec['p_value']:.6g}\")\n",
    "    print(f\"\\nBest: K={best['K']}, p-value={best['p_value']:.6g}, KS={best['ks_stat']:.6g}\")\n",
    "    return best, results, best[\"pi\"], best[\"mu\"], best[\"sigma\"], best[\"r\"], best[\"b\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
